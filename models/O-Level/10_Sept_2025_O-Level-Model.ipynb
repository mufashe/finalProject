{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json, os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# -------------------- Config --------------------\n",
    "DATA_PATH = \"O_Level_Dataset_with_Schools.csv\"  # change if needed\n",
    "MODEL_DIR = Path(\"models/olevel\")\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SUBJECTS = [\n",
    "    \"Mathematics\",\"Physics\",\"Chemistry\",\"Biology\",\"Geography\",\n",
    "    \"History\",\"Economics\",\"English\",\"Kinyarwanda\",\"ICT\"\n",
    "]\n",
    "YEARS = [\"S1\",\"S2\",\"S3\"]\n",
    "TARGET = \"A_Level_Stream\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def required_cols():\n",
    "    cols = []\n",
    "    for y in YEARS:\n",
    "        for s in SUBJECTS:\n",
    "            cols.append(f\"{y}_{s}\")\n",
    "    return cols\n",
    "\n",
    "REQ_COLS = required_cols()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# -------------------- Load & validate --------------------\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "missing = [c for c in REQ_COLS + [TARGET] if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required columns: {missing}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Drop rows with NA in features/target\n",
    "df = df.dropna(subset=REQ_COLS + [TARGET]).copy()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# -------------------- Encode target --------------------\n",
    "le_stream = LabelEncoder()\n",
    "df[\"A_Level_Stream_Label\"] = le_stream.fit_transform(df[TARGET])\n",
    "n_classes = int(df[\"A_Level_Stream_Label\"].nunique())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# -------------------- Split --------------------\n",
    "train_df, test_df = train_test_split(\n",
    "    df, test_size=0.2, stratify=df[\"A_Level_Stream_Label\"], random_state=42\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# -------------------- Scale features (FIT ON TRAIN ONLY) --------------------\n",
    "scaler = MinMaxScaler()\n",
    "train_df[REQ_COLS] = scaler.fit_transform(train_df[REQ_COLS])\n",
    "test_df[REQ_COLS]  = scaler.transform(test_df[REQ_COLS])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# -------------------- Build sequences (LSTM) --------------------\n",
    "def make_lstm_sequences(fr):\n",
    "    seqs = []\n",
    "    for _, row in fr.iterrows():\n",
    "        steps = []\n",
    "        for y in YEARS:\n",
    "            steps.append([row[f\"{y}_{s}\"] for s in SUBJECTS])\n",
    "        seqs.append(steps)\n",
    "    return np.asarray(seqs, dtype=\"float32\")\n",
    "\n",
    "X_train_seq = make_lstm_sequences(train_df)     # (N, 3, 10)\n",
    "y_train = train_df[\"A_Level_Stream_Label\"].to_numpy()\n",
    "X_test_seq  = make_lstm_sequences(test_df)\n",
    "y_test  = test_df[\"A_Level_Stream_Label\"].to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# -------------------- Random Forest on flattened --------------------\n",
    "X_train_rf = X_train_seq.reshape((X_train_seq.shape[0], -1))\n",
    "X_test_rf  = X_test_seq.reshape((X_test_seq.shape[0], -1))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Random Forest ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         HEG       0.91      0.84      0.87      1546\n",
      "         HEL       0.86      0.89      0.88      2203\n",
      "         HGL       0.86      0.89      0.88      2345\n",
      "         ICT       0.86      0.90      0.88      2497\n",
      "         MCE       0.91      0.84      0.87      1307\n",
      "         MEG       0.91      0.82      0.86      1445\n",
      "         PCB       0.87      0.90      0.89      2237\n",
      "         PCM       0.88      0.91      0.89      1864\n",
      "\n",
      "    accuracy                           0.88     15444\n",
      "   macro avg       0.88      0.87      0.88     15444\n",
      "weighted avg       0.88      0.88      0.88     15444\n",
      "\n",
      "RF Accuracy: 0.8785288785288785\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rf.fit(X_train_rf, y_train)\n",
    "y_pred_rf = rf.predict(X_test_rf)\n",
    "print(\"\\n=== Random Forest ===\")\n",
    "print(classification_report(y_test, y_pred_rf, target_names=le_stream.classes_))\n",
    "print(\"RF Accuracy:\", accuracy_score(y_test, y_pred_rf))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python310\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Python310\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/40\n",
      "WARNING:tensorflow:From C:\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "773/773 - 10s - loss: 1.7357 - accuracy: 0.3427 - val_loss: 1.1240 - val_accuracy: 0.6780 - 10s/epoch - 13ms/step\n",
      "Epoch 2/40\n",
      "773/773 - 4s - loss: 0.9683 - accuracy: 0.6356 - val_loss: 0.6725 - val_accuracy: 0.7838 - 4s/epoch - 5ms/step\n",
      "Epoch 3/40\n",
      "773/773 - 5s - loss: 0.7207 - accuracy: 0.7232 - val_loss: 0.4750 - val_accuracy: 0.8563 - 5s/epoch - 7ms/step\n",
      "Epoch 4/40\n",
      "773/773 - 6s - loss: 0.6254 - accuracy: 0.7577 - val_loss: 0.4206 - val_accuracy: 0.8617 - 6s/epoch - 7ms/step\n",
      "Epoch 5/40\n",
      "773/773 - 6s - loss: 0.5683 - accuracy: 0.7788 - val_loss: 0.4035 - val_accuracy: 0.8600 - 6s/epoch - 7ms/step\n",
      "Epoch 6/40\n",
      "773/773 - 7s - loss: 0.5268 - accuracy: 0.7935 - val_loss: 0.3455 - val_accuracy: 0.8870 - 7s/epoch - 9ms/step\n",
      "Epoch 7/40\n",
      "773/773 - 9s - loss: 0.4961 - accuracy: 0.8059 - val_loss: 0.3234 - val_accuracy: 0.8918 - 9s/epoch - 12ms/step\n",
      "Epoch 8/40\n",
      "773/773 - 9s - loss: 0.4791 - accuracy: 0.8157 - val_loss: 0.3047 - val_accuracy: 0.8979 - 9s/epoch - 11ms/step\n",
      "Epoch 9/40\n",
      "773/773 - 6s - loss: 0.4658 - accuracy: 0.8189 - val_loss: 0.2859 - val_accuracy: 0.9090 - 6s/epoch - 8ms/step\n",
      "Epoch 10/40\n",
      "773/773 - 6s - loss: 0.4562 - accuracy: 0.8224 - val_loss: 0.2835 - val_accuracy: 0.9107 - 6s/epoch - 8ms/step\n",
      "Epoch 11/40\n",
      "773/773 - 6s - loss: 0.4488 - accuracy: 0.8265 - val_loss: 0.2706 - val_accuracy: 0.9164 - 6s/epoch - 8ms/step\n",
      "Epoch 12/40\n",
      "773/773 - 6s - loss: 0.4332 - accuracy: 0.8331 - val_loss: 0.2733 - val_accuracy: 0.9072 - 6s/epoch - 8ms/step\n",
      "Epoch 13/40\n",
      "773/773 - 5s - loss: 0.4274 - accuracy: 0.8360 - val_loss: 0.2755 - val_accuracy: 0.8985 - 5s/epoch - 7ms/step\n",
      "Epoch 14/40\n",
      "773/773 - 6s - loss: 0.4173 - accuracy: 0.8395 - val_loss: 0.2664 - val_accuracy: 0.9065 - 6s/epoch - 7ms/step\n",
      "Epoch 15/40\n",
      "773/773 - 6s - loss: 0.4084 - accuracy: 0.8433 - val_loss: 0.2895 - val_accuracy: 0.8894 - 6s/epoch - 8ms/step\n",
      "Epoch 16/40\n",
      "773/773 - 6s - loss: 0.4098 - accuracy: 0.8423 - val_loss: 0.2407 - val_accuracy: 0.9218 - 6s/epoch - 8ms/step\n",
      "Epoch 17/40\n",
      "773/773 - 6s - loss: 0.4037 - accuracy: 0.8454 - val_loss: 0.2437 - val_accuracy: 0.9172 - 6s/epoch - 8ms/step\n",
      "Epoch 18/40\n",
      "773/773 - 6s - loss: 0.4018 - accuracy: 0.8452 - val_loss: 0.2431 - val_accuracy: 0.9170 - 6s/epoch - 8ms/step\n",
      "Epoch 19/40\n",
      "773/773 - 6s - loss: 0.3969 - accuracy: 0.8485 - val_loss: 0.2574 - val_accuracy: 0.9035 - 6s/epoch - 7ms/step\n",
      "Epoch 20/40\n",
      "773/773 - 6s - loss: 0.3848 - accuracy: 0.8507 - val_loss: 0.2359 - val_accuracy: 0.9203 - 6s/epoch - 8ms/step\n",
      "Epoch 21/40\n",
      "773/773 - 6s - loss: 0.3805 - accuracy: 0.8537 - val_loss: 0.2241 - val_accuracy: 0.9253 - 6s/epoch - 8ms/step\n",
      "Epoch 22/40\n",
      "773/773 - 6s - loss: 0.3748 - accuracy: 0.8582 - val_loss: 0.2111 - val_accuracy: 0.9373 - 6s/epoch - 8ms/step\n",
      "Epoch 23/40\n",
      "773/773 - 5s - loss: 0.3681 - accuracy: 0.8594 - val_loss: 0.2256 - val_accuracy: 0.9212 - 5s/epoch - 7ms/step\n",
      "Epoch 24/40\n",
      "773/773 - 6s - loss: 0.3673 - accuracy: 0.8602 - val_loss: 0.2200 - val_accuracy: 0.9236 - 6s/epoch - 8ms/step\n",
      "Epoch 25/40\n",
      "773/773 - 6s - loss: 0.3634 - accuracy: 0.8616 - val_loss: 0.2129 - val_accuracy: 0.9272 - 6s/epoch - 8ms/step\n",
      "Epoch 26/40\n",
      "773/773 - 6s - loss: 0.3560 - accuracy: 0.8642 - val_loss: 0.2087 - val_accuracy: 0.9300 - 6s/epoch - 8ms/step\n",
      "Epoch 27/40\n",
      "773/773 - 6s - loss: 0.3553 - accuracy: 0.8644 - val_loss: 0.2129 - val_accuracy: 0.9264 - 6s/epoch - 8ms/step\n",
      "Epoch 28/40\n",
      "773/773 - 6s - loss: 0.3503 - accuracy: 0.8658 - val_loss: 0.2166 - val_accuracy: 0.9213 - 6s/epoch - 7ms/step\n",
      "Epoch 29/40\n",
      "773/773 - 5s - loss: 0.3477 - accuracy: 0.8661 - val_loss: 0.2147 - val_accuracy: 0.9243 - 5s/epoch - 7ms/step\n",
      "Epoch 30/40\n",
      "773/773 - 6s - loss: 0.3468 - accuracy: 0.8666 - val_loss: 0.1977 - val_accuracy: 0.9369 - 6s/epoch - 8ms/step\n",
      "Epoch 31/40\n",
      "773/773 - 6s - loss: 0.3415 - accuracy: 0.8701 - val_loss: 0.2119 - val_accuracy: 0.9281 - 6s/epoch - 7ms/step\n",
      "Epoch 32/40\n",
      "773/773 - 6s - loss: 0.3365 - accuracy: 0.8725 - val_loss: 0.2241 - val_accuracy: 0.9170 - 6s/epoch - 7ms/step\n",
      "Epoch 33/40\n",
      "773/773 - 5s - loss: 0.3365 - accuracy: 0.8707 - val_loss: 0.2068 - val_accuracy: 0.9249 - 5s/epoch - 7ms/step\n",
      "Epoch 34/40\n",
      "773/773 - 6s - loss: 0.3338 - accuracy: 0.8735 - val_loss: 0.1955 - val_accuracy: 0.9313 - 6s/epoch - 7ms/step\n",
      "Epoch 35/40\n",
      "773/773 - 6s - loss: 0.3274 - accuracy: 0.8750 - val_loss: 0.2116 - val_accuracy: 0.9200 - 6s/epoch - 8ms/step\n",
      "Epoch 36/40\n",
      "773/773 - 5s - loss: 0.3256 - accuracy: 0.8744 - val_loss: 0.1963 - val_accuracy: 0.9315 - 5s/epoch - 6ms/step\n",
      "Epoch 37/40\n",
      "773/773 - 4s - loss: 0.3200 - accuracy: 0.8767 - val_loss: 0.1892 - val_accuracy: 0.9340 - 4s/epoch - 6ms/step\n",
      "Epoch 38/40\n",
      "773/773 - 6s - loss: 0.3168 - accuracy: 0.8778 - val_loss: 0.2107 - val_accuracy: 0.9198 - 6s/epoch - 8ms/step\n",
      "Epoch 39/40\n",
      "773/773 - 6s - loss: 0.3190 - accuracy: 0.8760 - val_loss: 0.1930 - val_accuracy: 0.9294 - 6s/epoch - 7ms/step\n",
      "Epoch 40/40\n",
      "773/773 - 6s - loss: 0.3138 - accuracy: 0.8807 - val_loss: 0.1908 - val_accuracy: 0.9302 - 6s/epoch - 7ms/step\n",
      "483/483 [==============================] - 2s 4ms/step\n",
      "\n",
      "=== LSTM ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         HEG       0.85      0.98      0.91      1546\n",
      "         HEL       0.96      0.93      0.94      2203\n",
      "         HGL       0.97      0.92      0.95      2345\n",
      "         ICT       0.97      0.95      0.96      2497\n",
      "         MCE       0.89      0.91      0.90      1307\n",
      "         MEG       0.89      0.98      0.93      1445\n",
      "         PCB       0.95      0.94      0.94      2237\n",
      "         PCM       0.97      0.88      0.92      1864\n",
      "\n",
      "    accuracy                           0.94     15444\n",
      "   macro avg       0.93      0.94      0.93     15444\n",
      "weighted avg       0.94      0.94      0.94     15444\n",
      "\n",
      "LSTM Accuracy: 0.9358974358974359\n"
     ]
    }
   ],
   "source": [
    "# -------------------- LSTM (sequence classifier) --------------------\n",
    "input_shape = (len(YEARS), len(SUBJECTS))\n",
    "lstm = models.Sequential([\n",
    "    layers.Input(shape=input_shape),\n",
    "    layers.LSTM(64, return_sequences=False),\n",
    "    layers.Dense(32, activation=\"relu\"),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(n_classes, activation=\"softmax\"),\n",
    "])\n",
    "lstm.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "early = callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "hist = lstm.fit(\n",
    "    X_train_seq, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=40, batch_size=64,\n",
    "    callbacks=[early], verbose=2\n",
    ")\n",
    "\n",
    "y_pred_lstm = np.argmax(lstm.predict(X_test_seq), axis=1)\n",
    "print(\"\\n=== LSTM ===\")\n",
    "print(classification_report(y_test, y_pred_lstm, target_names=le_stream.classes_))\n",
    "print(\"LSTM Accuracy:\", accuracy_score(y_test, y_pred_lstm))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "483/483 [==============================] - 2s 3ms/step\n",
      "\n",
      "=== Ensemble (avg) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         HEG       0.88      0.98      0.93      1546\n",
      "         HEL       0.96      0.95      0.95      2203\n",
      "         HGL       0.97      0.94      0.95      2345\n",
      "         ICT       0.97      0.95      0.96      2497\n",
      "         MCE       0.91      0.92      0.91      1307\n",
      "         MEG       0.90      0.97      0.94      1445\n",
      "         PCB       0.96      0.95      0.95      2237\n",
      "         PCM       0.97      0.90      0.94      1864\n",
      "\n",
      "    accuracy                           0.94     15444\n",
      "   macro avg       0.94      0.94      0.94     15444\n",
      "weighted avg       0.95      0.94      0.94     15444\n",
      "\n",
      "Ensemble Accuracy: 0.9446386946386947\n"
     ]
    }
   ],
   "source": [
    "# -------------------- Soft-voting ensemble --------------------\n",
    "lstm_probs = lstm.predict(X_test_seq)\n",
    "rf_probs   = rf.predict_proba(X_test_rf)\n",
    "ens_probs  = (lstm_probs + rf_probs) / 2.0\n",
    "y_pred_ens = np.argmax(ens_probs, axis=1)\n",
    "print(\"\\n=== Ensemble (avg) ===\")\n",
    "print(classification_report(y_test, y_pred_ens, target_names=le_stream.classes_))\n",
    "print(\"Ensemble Accuracy:\", accuracy_score(y_test, y_pred_ens))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved to D:\\Projects\\bigDataFinalProject\\finalProject\\models\\O-Level\\models\\olevel\n"
     ]
    }
   ],
   "source": [
    "# -------------------- Save artifacts --------------------\n",
    "joblib.dump(rf, MODEL_DIR / \"olevel_rf.pkl\")\n",
    "lstm.save(MODEL_DIR / \"olevel_lstm.keras\")\n",
    "joblib.dump(scaler, MODEL_DIR / \"olevel_scaler.pkl\")\n",
    "joblib.dump(le_stream, MODEL_DIR / \"olevel_label_encoder.pkl\")\n",
    "\n",
    "meta = {\n",
    "    \"subjects\": SUBJECTS,\n",
    "    \"years\": YEARS,\n",
    "    \"target\": TARGET,\n",
    "    \"classes\": le_stream.classes_.tolist(),\n",
    "    \"required_columns\": REQ_COLS,\n",
    "}\n",
    "with open(MODEL_DIR / \"olevel_meta.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(meta, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"\\nSaved to {MODEL_DIR.resolve()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}