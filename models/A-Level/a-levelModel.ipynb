{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.metrics import classification_report\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Load data\n",
    "# df = pd.read_csv(\"alevel_dataset.csv\")\n",
    "df = pd.read_csv(\"simulated_alevel_dataset_5.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "  student_id  academic_year  gender school_location residence_location  \\\n0     S00001           1994  female           urban              rural   \n1     S00002           1994    male           urban              urban   \n2     S00003           1994  female           rural              rural   \n3     S00004           1994  female           rural              rural   \n4     S00005           1994    male           urban              rural   \n5     S00006           1994  female           urban              urban   \n6     S00007           1994    male           urban              urban   \n7     S00008           1994  female           rural              rural   \n8     S00009           1994    male           urban              rural   \n9     S00010           1994    male           rural              rural   \n\n  school_type is_boarding  revision_hours_per_day  distance_to_school_km  \\\n0      public          no                    2.34                   0.82   \n1      public         yes                    4.05                   0.00   \n2     private          no                    1.46                   1.59   \n3      public          no                    2.03                   1.84   \n4      public          no                    1.99                   1.81   \n5     private          no                    2.65                   1.45   \n6      public         yes                    4.02                   0.00   \n7      public         yes                    3.76                   0.00   \n8     private          no                    1.38                   0.78   \n9     private         yes                    2.57                   0.00   \n\n  has_electricity  ... S6_Geography S4_Economics  S5_Economics S6_Economics  \\\n0             yes  ...         61.0         60.6          55.6         59.2   \n1             yes  ...         62.6         66.7          70.7         74.2   \n2              no  ...         71.9         73.4          77.3         77.3   \n3              no  ...         68.8         66.8          68.9         76.4   \n4              no  ...         62.5         64.3          61.9         64.4   \n5             yes  ...         66.0         65.5          68.3         74.3   \n6             yes  ...         61.1         65.5          68.7         74.4   \n7              no  ...         69.1         66.0          69.1         66.0   \n8              no  ...         62.3         66.6          66.7         72.6   \n9             yes  ...         60.3         65.0          62.0         62.1   \n\n   S4_Computer  S5_Computer  S6_Computer  S4_History  S5_History  S6_History  \n0         52.4         51.6         53.5        70.0        72.7        72.1  \n1         69.5         71.5         70.4        66.5        62.6        62.9  \n2         77.1         80.6         83.0        71.1        72.2        76.3  \n3         65.6         71.9         72.5        64.2        65.7        67.6  \n4         61.6         64.1         67.9        68.4        66.8        69.3  \n5         60.5         58.8         59.3        64.9        68.1        67.2  \n6         61.0         64.9         66.6        70.5        70.5        69.5  \n7         66.2         65.0         64.9        82.7        83.0        86.9  \n8         69.8         71.7         70.9        61.2        57.7        55.5  \n9         69.1         73.4         74.8        63.9        64.9        67.7  \n\n[10 rows x 38 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>student_id</th>\n      <th>academic_year</th>\n      <th>gender</th>\n      <th>school_location</th>\n      <th>residence_location</th>\n      <th>school_type</th>\n      <th>is_boarding</th>\n      <th>revision_hours_per_day</th>\n      <th>distance_to_school_km</th>\n      <th>has_electricity</th>\n      <th>...</th>\n      <th>S6_Geography</th>\n      <th>S4_Economics</th>\n      <th>S5_Economics</th>\n      <th>S6_Economics</th>\n      <th>S4_Computer</th>\n      <th>S5_Computer</th>\n      <th>S6_Computer</th>\n      <th>S4_History</th>\n      <th>S5_History</th>\n      <th>S6_History</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>S00001</td>\n      <td>1994</td>\n      <td>female</td>\n      <td>urban</td>\n      <td>rural</td>\n      <td>public</td>\n      <td>no</td>\n      <td>2.34</td>\n      <td>0.82</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>61.0</td>\n      <td>60.6</td>\n      <td>55.6</td>\n      <td>59.2</td>\n      <td>52.4</td>\n      <td>51.6</td>\n      <td>53.5</td>\n      <td>70.0</td>\n      <td>72.7</td>\n      <td>72.1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>S00002</td>\n      <td>1994</td>\n      <td>male</td>\n      <td>urban</td>\n      <td>urban</td>\n      <td>public</td>\n      <td>yes</td>\n      <td>4.05</td>\n      <td>0.00</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>62.6</td>\n      <td>66.7</td>\n      <td>70.7</td>\n      <td>74.2</td>\n      <td>69.5</td>\n      <td>71.5</td>\n      <td>70.4</td>\n      <td>66.5</td>\n      <td>62.6</td>\n      <td>62.9</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>S00003</td>\n      <td>1994</td>\n      <td>female</td>\n      <td>rural</td>\n      <td>rural</td>\n      <td>private</td>\n      <td>no</td>\n      <td>1.46</td>\n      <td>1.59</td>\n      <td>no</td>\n      <td>...</td>\n      <td>71.9</td>\n      <td>73.4</td>\n      <td>77.3</td>\n      <td>77.3</td>\n      <td>77.1</td>\n      <td>80.6</td>\n      <td>83.0</td>\n      <td>71.1</td>\n      <td>72.2</td>\n      <td>76.3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>S00004</td>\n      <td>1994</td>\n      <td>female</td>\n      <td>rural</td>\n      <td>rural</td>\n      <td>public</td>\n      <td>no</td>\n      <td>2.03</td>\n      <td>1.84</td>\n      <td>no</td>\n      <td>...</td>\n      <td>68.8</td>\n      <td>66.8</td>\n      <td>68.9</td>\n      <td>76.4</td>\n      <td>65.6</td>\n      <td>71.9</td>\n      <td>72.5</td>\n      <td>64.2</td>\n      <td>65.7</td>\n      <td>67.6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>S00005</td>\n      <td>1994</td>\n      <td>male</td>\n      <td>urban</td>\n      <td>rural</td>\n      <td>public</td>\n      <td>no</td>\n      <td>1.99</td>\n      <td>1.81</td>\n      <td>no</td>\n      <td>...</td>\n      <td>62.5</td>\n      <td>64.3</td>\n      <td>61.9</td>\n      <td>64.4</td>\n      <td>61.6</td>\n      <td>64.1</td>\n      <td>67.9</td>\n      <td>68.4</td>\n      <td>66.8</td>\n      <td>69.3</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>S00006</td>\n      <td>1994</td>\n      <td>female</td>\n      <td>urban</td>\n      <td>urban</td>\n      <td>private</td>\n      <td>no</td>\n      <td>2.65</td>\n      <td>1.45</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>66.0</td>\n      <td>65.5</td>\n      <td>68.3</td>\n      <td>74.3</td>\n      <td>60.5</td>\n      <td>58.8</td>\n      <td>59.3</td>\n      <td>64.9</td>\n      <td>68.1</td>\n      <td>67.2</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>S00007</td>\n      <td>1994</td>\n      <td>male</td>\n      <td>urban</td>\n      <td>urban</td>\n      <td>public</td>\n      <td>yes</td>\n      <td>4.02</td>\n      <td>0.00</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>61.1</td>\n      <td>65.5</td>\n      <td>68.7</td>\n      <td>74.4</td>\n      <td>61.0</td>\n      <td>64.9</td>\n      <td>66.6</td>\n      <td>70.5</td>\n      <td>70.5</td>\n      <td>69.5</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>S00008</td>\n      <td>1994</td>\n      <td>female</td>\n      <td>rural</td>\n      <td>rural</td>\n      <td>public</td>\n      <td>yes</td>\n      <td>3.76</td>\n      <td>0.00</td>\n      <td>no</td>\n      <td>...</td>\n      <td>69.1</td>\n      <td>66.0</td>\n      <td>69.1</td>\n      <td>66.0</td>\n      <td>66.2</td>\n      <td>65.0</td>\n      <td>64.9</td>\n      <td>82.7</td>\n      <td>83.0</td>\n      <td>86.9</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>S00009</td>\n      <td>1994</td>\n      <td>male</td>\n      <td>urban</td>\n      <td>rural</td>\n      <td>private</td>\n      <td>no</td>\n      <td>1.38</td>\n      <td>0.78</td>\n      <td>no</td>\n      <td>...</td>\n      <td>62.3</td>\n      <td>66.6</td>\n      <td>66.7</td>\n      <td>72.6</td>\n      <td>69.8</td>\n      <td>71.7</td>\n      <td>70.9</td>\n      <td>61.2</td>\n      <td>57.7</td>\n      <td>55.5</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>S00010</td>\n      <td>1994</td>\n      <td>male</td>\n      <td>rural</td>\n      <td>rural</td>\n      <td>private</td>\n      <td>yes</td>\n      <td>2.57</td>\n      <td>0.00</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>60.3</td>\n      <td>65.0</td>\n      <td>62.0</td>\n      <td>62.1</td>\n      <td>69.1</td>\n      <td>73.4</td>\n      <td>74.8</td>\n      <td>63.9</td>\n      <td>64.9</td>\n      <td>67.7</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows Ã— 38 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Encode categorical columns\n",
    "cat_cols = [\"gender\", \"school_location\", \"residence_location\", \"school_type\",\n",
    "            \"is_boarding\", \"has_electricity\", \"parent_status\", \"extracurricular\"]\n",
    "\n",
    "for col in cat_cols:\n",
    "    df[col] = LabelEncoder().fit_transform(df[col])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Target encoding\n",
    "target_col = \"predicted_university_subject\"\n",
    "target_encoder = LabelEncoder()\n",
    "df[target_col] = target_encoder.fit_transform(df[target_col])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "['target_encoder.pkl']"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save for future decoding\n",
    "joblib.dump(target_encoder, \"target_encoder.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Split features and target\n",
    "X = df.drop(columns=[\"student_id\", \"predicted_university_subject\"])\n",
    "y = df[\"predicted_university_subject\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Normalize features\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, stratify=y, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#  LSTM Model for Sequential Learning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Prepare time series data\n",
    "def reshape_for_lstm(df, subjects):\n",
    "    sequences = []\n",
    "    for i in range(len(df)):\n",
    "        seq = []\n",
    "        for year in [\"S4\", \"S5\", \"S6\"]:\n",
    "            seq.append([df[f\"{year}_{sub}\"].iloc[i] for sub in subjects])\n",
    "        sequences.append(seq)\n",
    "    return np.array(sequences)\n",
    "\n",
    "\n",
    "subjects = [\"Math\", \"Physics\", \"Chemistry\", \"Biology\", \"Geography\", \"Economics\", \"Computer\", \"History\"]\n",
    "X_seq = reshape_for_lstm(df, subjects)\n",
    "y_seq = y.values\n",
    "\n",
    "X_seq_train, X_seq_test, y_seq_train, y_seq_test = train_test_split(X_seq, y_seq, stratify=y_seq, test_size=0.2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python310\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build LSTM model\n",
    "lstm_model = models.Sequential([\n",
    "    layers.Input(shape=(3, len(subjects))),\n",
    "    layers.LSTM(64, return_sequences=False),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(len(np.unique(y_seq)), activation='softmax')\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python310\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:From C:\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "2400/2400 [==============================] - 19s 7ms/step - loss: 0.9855 - accuracy: 0.5992 - val_loss: 0.7447 - val_accuracy: 0.7122\n",
      "Epoch 2/30\n",
      "2400/2400 [==============================] - 12s 5ms/step - loss: 0.5582 - accuracy: 0.7770 - val_loss: 0.4276 - val_accuracy: 0.8320\n",
      "Epoch 3/30\n",
      "2400/2400 [==============================] - 12s 5ms/step - loss: 0.4433 - accuracy: 0.8219 - val_loss: 0.4824 - val_accuracy: 0.8083\n",
      "Epoch 4/30\n",
      "2400/2400 [==============================] - 26s 11ms/step - loss: 0.3883 - accuracy: 0.8415 - val_loss: 0.3009 - val_accuracy: 0.8787\n",
      "Epoch 5/30\n",
      "2400/2400 [==============================] - 27s 11ms/step - loss: 0.3717 - accuracy: 0.8477 - val_loss: 0.3218 - val_accuracy: 0.8714\n",
      "Epoch 6/30\n",
      "2400/2400 [==============================] - 32s 13ms/step - loss: 0.3419 - accuracy: 0.8597 - val_loss: 0.4003 - val_accuracy: 0.8382\n",
      "Epoch 7/30\n",
      "2400/2400 [==============================] - 25s 10ms/step - loss: 0.3369 - accuracy: 0.8602 - val_loss: 0.2525 - val_accuracy: 0.8967\n",
      "Epoch 8/30\n",
      "2400/2400 [==============================] - 15s 6ms/step - loss: 0.3302 - accuracy: 0.8647 - val_loss: 0.3229 - val_accuracy: 0.8681\n",
      "Epoch 9/30\n",
      "2400/2400 [==============================] - 13s 5ms/step - loss: 0.3073 - accuracy: 0.8733 - val_loss: 0.4047 - val_accuracy: 0.8334\n",
      "Epoch 10/30\n",
      "2400/2400 [==============================] - 15s 6ms/step - loss: 0.3035 - accuracy: 0.8748 - val_loss: 0.2100 - val_accuracy: 0.9216\n",
      "Epoch 11/30\n",
      "2400/2400 [==============================] - 15s 6ms/step - loss: 0.3012 - accuracy: 0.8754 - val_loss: 0.2470 - val_accuracy: 0.8958\n",
      "Epoch 12/30\n",
      "2400/2400 [==============================] - 15s 6ms/step - loss: 0.2814 - accuracy: 0.8840 - val_loss: 0.2967 - val_accuracy: 0.8707\n",
      "Epoch 13/30\n",
      "2400/2400 [==============================] - 12s 5ms/step - loss: 0.2725 - accuracy: 0.8877 - val_loss: 0.3620 - val_accuracy: 0.8519\n",
      "Epoch 14/30\n",
      "2400/2400 [==============================] - 11s 5ms/step - loss: 0.2753 - accuracy: 0.8851 - val_loss: 0.3737 - val_accuracy: 0.8455\n",
      "Epoch 15/30\n",
      "2400/2400 [==============================] - 12s 5ms/step - loss: 0.2655 - accuracy: 0.8902 - val_loss: 0.1896 - val_accuracy: 0.9246\n",
      "Epoch 16/30\n",
      "2400/2400 [==============================] - 11s 4ms/step - loss: 0.2554 - accuracy: 0.8941 - val_loss: 0.2207 - val_accuracy: 0.9054\n",
      "Epoch 17/30\n",
      "2400/2400 [==============================] - 11s 4ms/step - loss: 0.2408 - accuracy: 0.9000 - val_loss: 0.2660 - val_accuracy: 0.8814\n",
      "Epoch 18/30\n",
      "2400/2400 [==============================] - 10s 4ms/step - loss: 0.2476 - accuracy: 0.8972 - val_loss: 0.3223 - val_accuracy: 0.8626\n",
      "Epoch 19/30\n",
      "2400/2400 [==============================] - 14s 6ms/step - loss: 0.2529 - accuracy: 0.8945 - val_loss: 0.1704 - val_accuracy: 0.9315\n",
      "Epoch 20/30\n",
      "2400/2400 [==============================] - 11s 4ms/step - loss: 0.2412 - accuracy: 0.9010 - val_loss: 0.2050 - val_accuracy: 0.9111\n",
      "Epoch 21/30\n",
      "2400/2400 [==============================] - 13s 5ms/step - loss: 0.2421 - accuracy: 0.9000 - val_loss: 0.2074 - val_accuracy: 0.9083\n",
      "Epoch 22/30\n",
      "2400/2400 [==============================] - 11s 5ms/step - loss: 0.2354 - accuracy: 0.9025 - val_loss: 0.1908 - val_accuracy: 0.9184\n",
      "Epoch 23/30\n",
      "2400/2400 [==============================] - 11s 5ms/step - loss: 0.2292 - accuracy: 0.9039 - val_loss: 0.2383 - val_accuracy: 0.8976\n",
      "Epoch 24/30\n",
      "2400/2400 [==============================] - 16s 7ms/step - loss: 0.2190 - accuracy: 0.9081 - val_loss: 0.1462 - val_accuracy: 0.9508\n",
      "Epoch 25/30\n",
      "2400/2400 [==============================] - 18s 7ms/step - loss: 0.2278 - accuracy: 0.9058 - val_loss: 0.3460 - val_accuracy: 0.8429\n",
      "Epoch 26/30\n",
      "2400/2400 [==============================] - 14s 6ms/step - loss: 0.2284 - accuracy: 0.9055 - val_loss: 0.2042 - val_accuracy: 0.9168\n",
      "Epoch 27/30\n",
      "2400/2400 [==============================] - 13s 5ms/step - loss: 0.2183 - accuracy: 0.9084 - val_loss: 0.2076 - val_accuracy: 0.9170\n",
      "Epoch 28/30\n",
      "2400/2400 [==============================] - 10s 4ms/step - loss: 0.2143 - accuracy: 0.9103 - val_loss: 0.1844 - val_accuracy: 0.9184\n",
      "Epoch 29/30\n",
      "2400/2400 [==============================] - 12s 5ms/step - loss: 0.2146 - accuracy: 0.9108 - val_loss: 0.2723 - val_accuracy: 0.8802\n",
      "Epoch 30/30\n",
      "2400/2400 [==============================] - 11s 5ms/step - loss: 0.2127 - accuracy: 0.9116 - val_loss: 0.1772 - val_accuracy: 0.9224\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x1ed12aaf970>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "lstm_model.fit(X_seq_train, y_seq_train, validation_split=0.2, epochs=30, batch_size=32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random Forest (Baseline Tabular Model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93      2822\n",
      "           1       0.96      0.98      0.97      4135\n",
      "           2       0.96      0.98      0.97      2684\n",
      "           3       0.96      0.99      0.98      8425\n",
      "           4       0.92      0.89      0.90      3456\n",
      "           5       0.93      0.83      0.88      2478\n",
      "\n",
      "    accuracy                           0.95     24000\n",
      "   macro avg       0.94      0.93      0.94     24000\n",
      "weighted avg       0.95      0.95      0.95     24000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_rf))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#  ARIMA (Optional for Subject-Specific Score Forecasting)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecasted S7_Math: 66.89762893346824\n"
     ]
    }
   ],
   "source": [
    "# Example: forecasting a single student's Math score sequence\n",
    "student_seq = df.iloc[0][[\"S4_Physics\", \"S5_Physics\", \"S6_Physics\"]].astype(float).values\n",
    "model = sm.tsa.ARIMA(student_seq, order=(1, 1, 0))\n",
    "model_fit = model.fit()\n",
    "forecast = model_fit.forecast()\n",
    "print(\"Forecasted S7_Math:\", forecast[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Ensemble Meta-Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 2s 2ms/step\n",
      "Ensemble Accuracy: 0.9497916666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Example: combine LSTM and RF predictions\n",
    "lstm_preds = lstm_model.predict(X_seq_test)\n",
    "lstm_preds_cls = np.argmax(lstm_preds, axis=1)\n",
    "\n",
    "# Stack and train a meta model\n",
    "meta_X = np.vstack([lstm_preds_cls, rf.predict(X_test)]).T\n",
    "meta_model = LogisticRegression()\n",
    "meta_model.fit(meta_X, y_test)\n",
    "\n",
    "meta_preds = meta_model.predict(meta_X)\n",
    "print(\"Ensemble Accuracy:\", accuracy_score(y_test, meta_preds))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Ensemble Model Evaluation ===\n",
      "Accuracy: 0.9497916666666667\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2634    0    0  129   43   16]\n",
      " [   0 4063    0    0   57   15]\n",
      " [   0    0 2641    0   34    9]\n",
      " [  59    0    0 8330   14   22]\n",
      " [  75   88   67   60 3082   84]\n",
      " [  47   83   57  119  127 2045]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93      2822\n",
      "           1       0.96      0.98      0.97      4135\n",
      "           2       0.96      0.98      0.97      2684\n",
      "           3       0.96      0.99      0.98      8425\n",
      "           4       0.92      0.89      0.90      3456\n",
      "           5       0.93      0.83      0.88      2478\n",
      "\n",
      "    accuracy                           0.95     24000\n",
      "   macro avg       0.94      0.93      0.94     24000\n",
      "weighted avg       0.95      0.95      0.95     24000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score\n",
    "\n",
    "# Predict with meta model\n",
    "meta_preds = meta_model.predict(meta_X)\n",
    "\n",
    "# Accuracy\n",
    "print(\"=== Ensemble Model Evaluation ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, meta_preds))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, meta_preds))\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, meta_preds))\n",
    "\n",
    "# Optional: ROC AUC for binary classification\n",
    "if len(np.unique(y_test)) == 2:\n",
    "    meta_probs = meta_model.predict_proba(meta_X)[:, 1]  # probability for class 1\n",
    "    print(\"ROC AUC:\", roc_auc_score(y_test, meta_probs))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "data": {
      "text/plain": "['target_encoder.pkl']"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assume you've trained these already\n",
    "joblib.dump(rf, \"rf_model.pkl\")\n",
    "joblib.dump(meta_model, \"meta_model.pkl\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "lstm_model.save(\"lstm_model.h5\")\n",
    "joblib.dump(target_col, \"target_encoder.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}