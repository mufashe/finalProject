{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "# === 1. Load the Dataset ===\n",
    "# df = pd.read_csv(\"simulated_rwanda_primary_promotions_1996_2023_V3.csv\")\n",
    "# df = pd.read_csv(\"simulated_rwanda_primary_promotions_1996_2023_V6_with_locations.csv\")\n",
    "df = pd.read_csv(\"simulated_rwanda_primary_promotions_1996_2023_with_locations_01.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# === 2. Prepare Features & Target ===\n",
    "# Use only up to P5 for prediction (simulate \"future\" forecast before P6 is known)\n",
    "subject_cols = []\n",
    "for grade in [\"P1\", \"P2\", \"P3\", \"P4\", \"P5\", \"P6\"]:\n",
    "    subject_cols += [f\"{subj}_{grade}\" for subj in\n",
    "                     [\"Kinyarwanda\", \"English\", \"Mathematics\", \"Science\", \"Social_Studies\", \"Creative_Arts\"]]\n",
    "\n",
    "demo_cols = [\n",
    "    \"Gender\", \"School_Location\", \"Residence_Location\",\n",
    "    \"Has_Electricity\", \"Parental_Education_Level\"\n",
    "]\n",
    "\n",
    "X = df[subject_cols + demo_cols].copy()\n",
    "y = df[\"Passed_National_Exam\"].astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# === 3. Encode Categorical Features ===\n",
    "for col in [\"Gender\", \"School_Location\", \"Residence_Location\", \"Parental_Education_Level\"]:\n",
    "    X[col] = LabelEncoder().fit_transform(X[col])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# Optional: Scale the features for logistic regression\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# === 4. Split Train/Test ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train_scaled, X_test_scaled = scaler.transform(X_train), scaler.transform(X_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# === 5. Train Models ===\n",
    "\n",
    "# -- Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# -- Logistic Regression\n",
    "logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "logreg_pred = logreg.predict(X_test_scaled)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Random Forest Results ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.78      0.84       310\n",
      "           1       0.98      0.99      0.98      2756\n",
      "\n",
      "    accuracy                           0.97      3066\n",
      "   macro avg       0.94      0.89      0.91      3066\n",
      "weighted avg       0.97      0.97      0.97      3066\n",
      "\n",
      "ROC AUC: 0.9911202537571984\n",
      "\n",
      "==== Logistic Regression Results ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92       310\n",
      "           1       0.99      0.99      0.99      2756\n",
      "\n",
      "    accuracy                           0.98      3066\n",
      "   macro avg       0.95      0.95      0.95      3066\n",
      "weighted avg       0.98      0.98      0.98      3066\n",
      "\n",
      "ROC AUC: 0.997738658176881\n"
     ]
    }
   ],
   "source": [
    "# === 6. Evaluate Models ===\n",
    "print(\"==== Random Forest Results ====\")\n",
    "print(classification_report(y_test, rf_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, rf.predict_proba(X_test)[:, 1]))\n",
    "\n",
    "print(\"\\n==== Logistic Regression Results ====\")\n",
    "print(classification_report(y_test, logreg_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, logreg.predict_proba(X_test_scaled)[:, 1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# Prepare LSTM input: reshape to (samples, timesteps, features)\n",
    "# Each subject per grade as a time step (P1â€“P5)\n",
    "n_subjects = 6\n",
    "X_seq = df[[f\"{subj}_{grade}\" for grade in [\"P1\", \"P2\", \"P3\", \"P4\", \"P5\"] for subj in\n",
    "            [\"Kinyarwanda\", \"English\", \"Mathematics\", \"Science\", \"Social_Studies\", \"Creative_Arts\"]]].values\n",
    "X_seq = X_seq.reshape(-1, 5, n_subjects)  # [samples, timesteps, features]\n",
    "y_seq = y.values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "# Split for LSTM\n",
    "idx = np.arange(X_seq.shape[0])\n",
    "train_idx, test_idx = train_test_split(idx, test_size=0.2, random_state=42, stratify=y_seq)\n",
    "X_seq_train, X_seq_test = X_seq[train_idx], X_seq[test_idx]\n",
    "y_seq_train, y_seq_test = y_seq[train_idx], y_seq[test_idx]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "307/307 - 4s - loss: 0.3001 - accuracy: 0.9009 - val_loss: 0.2077 - val_accuracy: 0.9213 - 4s/epoch - 12ms/step\n",
      "Epoch 2/30\n",
      "307/307 - 1s - loss: 0.1986 - accuracy: 0.9197 - val_loss: 0.1689 - val_accuracy: 0.9344 - 1s/epoch - 4ms/step\n",
      "Epoch 3/30\n",
      "307/307 - 1s - loss: 0.1777 - accuracy: 0.9268 - val_loss: 0.1891 - val_accuracy: 0.9250 - 1s/epoch - 4ms/step\n",
      "Epoch 4/30\n",
      "307/307 - 2s - loss: 0.1675 - accuracy: 0.9338 - val_loss: 0.1520 - val_accuracy: 0.9417 - 2s/epoch - 6ms/step\n",
      "Epoch 5/30\n",
      "307/307 - 1s - loss: 0.1590 - accuracy: 0.9347 - val_loss: 0.1448 - val_accuracy: 0.9433 - 1s/epoch - 5ms/step\n",
      "Epoch 6/30\n",
      "307/307 - 1s - loss: 0.1551 - accuracy: 0.9368 - val_loss: 0.1387 - val_accuracy: 0.9450 - 1s/epoch - 4ms/step\n",
      "Epoch 7/30\n",
      "307/307 - 1s - loss: 0.1569 - accuracy: 0.9363 - val_loss: 0.1602 - val_accuracy: 0.9323 - 1s/epoch - 4ms/step\n",
      "Epoch 8/30\n",
      "307/307 - 1s - loss: 0.1439 - accuracy: 0.9401 - val_loss: 0.1568 - val_accuracy: 0.9348 - 1s/epoch - 4ms/step\n",
      "Epoch 9/30\n",
      "307/307 - 1s - loss: 0.1448 - accuracy: 0.9393 - val_loss: 0.1408 - val_accuracy: 0.9409 - 1s/epoch - 4ms/step\n",
      "Epoch 10/30\n",
      "307/307 - 1s - loss: 0.1436 - accuracy: 0.9389 - val_loss: 0.1449 - val_accuracy: 0.9401 - 1s/epoch - 4ms/step\n",
      "Epoch 11/30\n",
      "307/307 - 2s - loss: 0.1437 - accuracy: 0.9403 - val_loss: 0.1602 - val_accuracy: 0.9340 - 2s/epoch - 5ms/step\n",
      "Epoch 12/30\n",
      "307/307 - 1s - loss: 0.1434 - accuracy: 0.9393 - val_loss: 0.1293 - val_accuracy: 0.9494 - 1s/epoch - 4ms/step\n",
      "Epoch 13/30\n",
      "307/307 - 2s - loss: 0.1402 - accuracy: 0.9404 - val_loss: 0.1375 - val_accuracy: 0.9454 - 2s/epoch - 7ms/step\n",
      "Epoch 14/30\n",
      "307/307 - 1s - loss: 0.1399 - accuracy: 0.9399 - val_loss: 0.1293 - val_accuracy: 0.9470 - 1s/epoch - 4ms/step\n",
      "Epoch 15/30\n",
      "307/307 - 1s - loss: 0.1357 - accuracy: 0.9412 - val_loss: 0.1275 - val_accuracy: 0.9523 - 1s/epoch - 4ms/step\n",
      "Epoch 16/30\n",
      "307/307 - 1s - loss: 0.1380 - accuracy: 0.9414 - val_loss: 0.1688 - val_accuracy: 0.9344 - 1s/epoch - 4ms/step\n",
      "Epoch 17/30\n",
      "307/307 - 1s - loss: 0.1367 - accuracy: 0.9410 - val_loss: 0.1283 - val_accuracy: 0.9490 - 1s/epoch - 4ms/step\n",
      "Epoch 18/30\n",
      "307/307 - 1s - loss: 0.1374 - accuracy: 0.9439 - val_loss: 0.1333 - val_accuracy: 0.9499 - 1s/epoch - 4ms/step\n",
      "Epoch 19/30\n",
      "307/307 - 1s - loss: 0.1359 - accuracy: 0.9448 - val_loss: 0.1232 - val_accuracy: 0.9511 - 1s/epoch - 4ms/step\n",
      "Epoch 20/30\n",
      "307/307 - 1s - loss: 0.1350 - accuracy: 0.9421 - val_loss: 0.1233 - val_accuracy: 0.9494 - 1s/epoch - 4ms/step\n",
      "Epoch 21/30\n",
      "307/307 - 1s - loss: 0.1339 - accuracy: 0.9435 - val_loss: 0.1231 - val_accuracy: 0.9507 - 1s/epoch - 4ms/step\n",
      "Epoch 22/30\n",
      "307/307 - 1s - loss: 0.1323 - accuracy: 0.9445 - val_loss: 0.1242 - val_accuracy: 0.9519 - 1s/epoch - 5ms/step\n",
      "Epoch 23/30\n",
      "307/307 - 1s - loss: 0.1366 - accuracy: 0.9433 - val_loss: 0.1266 - val_accuracy: 0.9515 - 1s/epoch - 4ms/step\n",
      "Epoch 24/30\n",
      "307/307 - 2s - loss: 0.1340 - accuracy: 0.9416 - val_loss: 0.1246 - val_accuracy: 0.9494 - 2s/epoch - 7ms/step\n",
      "Epoch 25/30\n",
      "307/307 - 1s - loss: 0.1314 - accuracy: 0.9436 - val_loss: 0.1340 - val_accuracy: 0.9437 - 1s/epoch - 4ms/step\n",
      "Epoch 26/30\n",
      "307/307 - 1s - loss: 0.1334 - accuracy: 0.9434 - val_loss: 0.1278 - val_accuracy: 0.9478 - 1s/epoch - 4ms/step\n",
      "Epoch 27/30\n",
      "307/307 - 1s - loss: 0.1313 - accuracy: 0.9432 - val_loss: 0.1224 - val_accuracy: 0.9515 - 1s/epoch - 4ms/step\n",
      "Epoch 28/30\n",
      "307/307 - 1s - loss: 0.1312 - accuracy: 0.9447 - val_loss: 0.1224 - val_accuracy: 0.9523 - 1s/epoch - 4ms/step\n",
      "Epoch 29/30\n",
      "307/307 - 1s - loss: 0.1297 - accuracy: 0.9454 - val_loss: 0.1301 - val_accuracy: 0.9470 - 1s/epoch - 4ms/step\n",
      "Epoch 30/30\n",
      "307/307 - 1s - loss: 0.1362 - accuracy: 0.9430 - val_loss: 0.1269 - val_accuracy: 0.9486 - 1s/epoch - 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# Simple LSTM\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(5, n_subjects)),\n",
    "    layers.LSTM(32, return_sequences=False),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_seq_train, y_seq_train, epochs=30, batch_size=32,\n",
    "                    validation_split=0.2, verbose=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 3ms/step\n",
      "\n",
      "==== LSTM Results ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.59      0.68       310\n",
      "           1       0.96      0.98      0.97      2756\n",
      "\n",
      "    accuracy                           0.94      3066\n",
      "   macro avg       0.87      0.79      0.82      3066\n",
      "weighted avg       0.94      0.94      0.94      3066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lstm_pred = (model.predict(X_seq_test) > 0.5).astype(int)\n",
    "print(\"\\n==== LSTM Results ====\")\n",
    "print(classification_report(y_seq_test, lstm_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved for later use.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(rf, \"primary_rf_model.pkl\")\n",
    "joblib.dump(logreg, \"primary_logreg_model.pkl\")\n",
    "joblib.dump(lstm_pred, \"primary_lstm_model.pkl\")\n",
    "print(\"Models saved for later use.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}